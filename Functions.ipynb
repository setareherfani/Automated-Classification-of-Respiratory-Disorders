{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statistics as stc\n",
    "from scipy.fftpack import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Antn_Data(file_name, root):\n",
    "\n",
    "    tokens = file_name.split('_')\n",
    "    \n",
    "    recording_info = pd.DataFrame(data = [tokens], columns = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment'])\n",
    "\n",
    "    recording_annotations = pd.read_csv(os.path.join(root, file_name), names = ['Start', 'End', 'Crackles', 'Wheezes'], delimiter= '\\t')\n",
    "\n",
    "    return (recording_info, recording_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast fourier transforfmation\n",
    "# background information from https://github.com/balzer82/FFT-Python\n",
    "def fft_m(signal,SR,MiDF,MaDF):\n",
    "\n",
    "    N=len(signal)\n",
    "    T=1/SR\n",
    "    Max=int((MaDF*(N//2))/(0.5*SR))\n",
    "    Min=int((MiDF*(N//2))/(0.5*SR))\n",
    "    yf = fft(signal)\n",
    "    xf = np.linspace(0, 1.0/(2.0*T),N//2)\n",
    "    Real_fft=2.0/N * np.abs(yf[0:N//2])   \n",
    "    xf=xf[Min:Max]\n",
    "    Real_fft=Real_fft[Min:Max]\n",
    "    psd=(Real_fft**2)/xf\n",
    "    return xf, Real_fft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean square envelope analysis\n",
    "# best option\n",
    "def Envelope_rms(inputSignal, window_size):    \n",
    "\n",
    "    a2 = np.power(inputSignal,2)\n",
    "\n",
    "    window = np.ones(window_size)/float(window_size)\n",
    "\n",
    "    Up=np.sqrt(np.convolve(a2, window, 'valid'))\n",
    "\n",
    "    Down=-np.sqrt(np.convolve(a2, window, 'valid'))\n",
    "\n",
    "    return Up,Down\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinational max min envelope analysis\n",
    "def Envelope_max_min(Signal,intervalLength,maxm):\n",
    "\n",
    "    Up=np.zeros(len(Signal))\n",
    "\n",
    "    Down=np.zeros(len(Signal))\n",
    "\n",
    "    for i in range(len(Signal)-intervalLength):\n",
    "\n",
    "        Up[i]=max(Signal[i:i+intervalLength])\n",
    "\n",
    "        Down[i]=min(Signal[i:i+intervalLength])\n",
    "\n",
    "    return Up,Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddest(Signal, axis=None):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Mean Absolute Deviation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return np.mean(np.absolute(Signal - np.mean(Signal, axis)), axis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMS(Signal, axis=None):\n",
    "\n",
    "    return np.sqrt(np.mean(Signal**2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FM4(Signal, axis=None):\n",
    "\n",
    "    return np.sqrt(np.mean(Signal**2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shape_factor(Signal, axis=None):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Shape_factor\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return len(Signal)*RMS(Signal)/sum(abs(Signal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nrm_Kurtosis(Signal, axis=None):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    normalized kurtosis\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return scipy.stats.kurtosis(Signal)/(np.std(Signal)**4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crest_factor(x):\n",
    "\n",
    "    return np.max(np.abs(x))/np.sqrt(np.mean(np.square(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impulse_factor(x):\n",
    "\n",
    "    return np.max(np.abs(x))/sum(abs(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Energy(x):\n",
    "\n",
    "    return sum(x**2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_pass_filter(X, low_cutoff, SR):\n",
    "\n",
    "    \n",
    "\n",
    "    sos = scipy.signal.butter(10, low_cutoff, 'highpass', SF, output='sos')\n",
    "\n",
    "    filtered_sig = scipy.signal.sosfilt(sos, X)\n",
    "\n",
    "\n",
    "\n",
    "    return filtered_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(X, high_cutoff, SR):\n",
    "\n",
    "    \n",
    "\n",
    "    sos = signal.butter(10, high_cutoff, 'lp', fs=SF, output='sos')\n",
    "\n",
    "    filtered_sig = scipy.signal.sosfilt(sos, X)\n",
    "\n",
    "\n",
    "\n",
    "    return filtered_sig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_wvlt( x, wavelet, level):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    1. Adapted from waveletSmooth function found here:\n",
    "\n",
    "    http://connor-johnson.com/2016/01/24/using-pywavelets-to-remove-high-frequency-noise/\n",
    "\n",
    "    2. Threshold equation and using hard mode in threshold as mentioned\n",
    "\n",
    "    by Tomas Vantuch:\n",
    "\n",
    "    http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Decompose to get the wavelet coefficients\n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "\n",
    "\n",
    "    # Calculate sigma for threshold as defined in http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "    # As noted by @harshit92 MAD referred to in the paper is Mean Absolute Deviation not Median Absolute Deviation\n",
    "\n",
    "    sigma = (1/0.6745) * maddest( coeff[-level])\n",
    "\n",
    "\n",
    "\n",
    "    # Calculte the univeral threshold\n",
    "    uthresh = sigma * np.sqrt( 2*np.log( len( x )))\n",
    "    coeff[1:] = (pywt.threshold( i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "\n",
    "    \n",
    "\n",
    "    # Reconstruct the signal using the thresholded coefficients\n",
    "\n",
    "    return pywt.waverec(coeff, wavelet, mode='per')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overnight code\n",
    "def Sound_features(Signal,SR):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Audio Spectral features\n",
    "\n",
    "    n_fft=2048, hop_length=512,frame_length=2048, spectral_power=2.0\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    chroma_mean= np.mean(librosa.feature.chroma_stft(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    chroma_std= np.std(librosa.feature.chroma_stft(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    cens_mean= np.mean(librosa.feature.chroma_cens(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    cens_std= np.std(librosa.feature.chroma_cens(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    mel_spctrm_mean= np.mean(librosa.feature.melspectrogram(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    mel_spctrm_std= np.std(librosa.feature.melspectrogram(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    mfcc_mean= np.mean(librosa.feature.mfcc(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    mfcc_std= np.std(librosa.feature.mfcc(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    spctl_rms= np.mean(librosa.feature.rms(Signal))\n",
    "\n",
    "    cntrd_mean= np.mean(librosa.feature.spectral_centroid(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    cntrd_std= np.std(librosa.feature.spectral_centroid(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    BW_mean= np.mean(librosa.feature.spectral_bandwidth(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    BW_std= np.std(librosa.feature.spectral_bandwidth(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    cntrst_mean= np.mean(librosa.feature.spectral_contrast(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    cntrst_std= np.std(librosa.feature.spectral_contrast(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    fltnss_mean= np.mean(librosa.feature.spectral_flatness(Signal).T, axis=0)\n",
    "\n",
    "    fltnss_std= np.std(librosa.feature.spectral_flatness(Signal).T, axis=0)\n",
    "\n",
    "    rolloff_mean= np.mean(librosa.feature.spectral_rolloff(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    rolloff_std= np.std(librosa.feature.spectral_rolloff(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    plyftr_mean= np.mean(librosa.feature.poly_features(Signal, sr=SR,order=10).T, axis=0)\n",
    "\n",
    "    plyftr_std= np.std(librosa.feature.poly_features(Signal, sr=SR,order=10).T, axis=0)\n",
    "\n",
    "    tonnetz_mean= np.mean(librosa.feature.tonnetz(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    tonnetz_std= np.std(librosa.feature.tonnetz(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    ZCrate_mean= np.mean(librosa.feature.zero_crossing_rate(Signal).T, axis=0)\n",
    "\n",
    "    ZCrate_std= np.std(librosa.feature.zero_crossing_rate(Signal).T, axis=0)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Audio Rhythm  features\n",
    "\n",
    "    n_fft=2048, hop_length=512,frame_length=2048, spectral_power=2.0\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tempogram_mean= np.mean(librosa.feature.tempogram(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    tempogram_std= np.std(librosa.feature.tempogram(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    FrTmpgrm_mean= np.mean(librosa.feature.fourier_tempogram(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    FrTmpgrm_std= np.std(librosa.feature.fourier_tempogram(Signal, sr=SR).T, axis=0)\n",
    "\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Manipulation feature\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    derivativ_mean= np.mean(librosa.feature.delta(Signal, order=1).T, axis=0)\n",
    "\n",
    "    derivativ_std= np.std(librosa.feature.delta(Signal, order=1).T, axis=0)\n",
    "\n",
    "    StckMmr_mean= np.mean(librosa.feature.stack_memory(Signal, n_steps=2,).T, axis=0)\n",
    "\n",
    "    StckMmr_std= np.std(librosa.feature.stack_memory(Signal, n_steps=2,).T, axis=0)    \n",
    "\n",
    "    Extracted_features=np.abs(np.hstack((chroma_mean,chroma_std, cens_mean, cens_std, mel_spctrm_mean, mel_spctrm_std, mfcc_mean, \n",
    "\n",
    "                              mfcc_std, spctl_rms, cntrd_mean, cntrd_std, \n",
    "\n",
    "                              BW_mean, BW_std, cntrst_mean, cntrst_std,\n",
    "\n",
    "                              fltnss_mean, fltnss_std, rolloff_mean, rolloff_std,\n",
    "\n",
    "                              plyftr_mean, plyftr_std, tonnetz_mean, tonnetz_std,\n",
    "\n",
    "                              ZCrate_mean, ZCrate_std, tempogram_mean,tempogram_std,\n",
    "\n",
    "                              FrTmpgrm_mean, FrTmpgrm_std, derivativ_mean, derivativ_std,\n",
    "\n",
    "                              StckMmr_mean, StckMmr_std)))\n",
    "\n",
    "    Extracted_features=Extracted_features.T\n",
    "# sound features \n",
    "    Features_name=pd.DataFrame(['chroma_mean','chroma_std', 'cens_mean', 'cens_std','mel_spctrm_mean', 'mel_spctrm_std', 'mfcc_mean', 'mfcc_std', 'spctl_rms', 'cntrd_mean', 'cntrd_std', 'BW_mean', 'BW_std', 'cntrst_mean', 'cntrst_std',\\\n",
    "\n",
    "                              'fltnss_mean', 'fltnss_std', 'rolloff_mean', 'rolloff_std',\\\n",
    "\n",
    "                              'plyftr_mean', 'plyftr_std', 'tonnetz_mean', 'tonnetz_std',\\\n",
    "\n",
    "                              'ZCrate_mean', 'ZCrate_std', 'tempogram_mean','tempogram_std',\\\n",
    "\n",
    "                              'FrTmpgrm_mean', 'FrTmpgrm_std', 'derivativ_mean', 'derivativ_std',\\\n",
    "\n",
    "                              'StckMmr_mean', 'StckMmr_std'])\n",
    "\n",
    "    \n",
    "\n",
    "    return Extracted_features,Features_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time_features(Signal,SR):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Statistical features from time domain signals\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    maxm=np.max(Signal) \n",
    "\n",
    "    mean=np.mean(Signal)             #Arithmetic mean of data.\n",
    "\n",
    "    h_mean=stc.harmonic_mean(abs(Signal))  #Harmonic mean of data.\n",
    "\n",
    "    median=stc.median(Signal)             #Median (middle value) of data.\n",
    "\n",
    "    m_low=stc.median_low(Signal)            #Low median of data.\n",
    "\n",
    "    m_h=stc.median_high(Signal)            # High median of data.\n",
    "\n",
    "    m_g=stc.median_grouped(Signal)           # Median, or 50th percentile of grouped data.\n",
    "\n",
    "    var=stc.pvariance(Signal)\n",
    "\n",
    "    std=np.std(Signal)\n",
    "\n",
    "    skewnss=scipy.stats.skew(Signal)\n",
    "\n",
    "    krts=scipy.stats.kurtosis(Signal)\n",
    "\n",
    "    Nkrts=Nrm_Kurtosis(Signal)\n",
    "\n",
    "    cumfreqs=scipy.stats.cumfreq(Signal)[0]\n",
    "\n",
    "    entrp=scipy.stats.entropy(abs(Signal))\n",
    "\n",
    "    shp_f=Shape_factor(Signal)\n",
    "\n",
    "    RMS_S=RMS(Signal)\n",
    "\n",
    "    mdst=maddest(Signal)\n",
    "\n",
    "    enrg=Energy(Signal)\n",
    "\n",
    "    IF=impulse_factor(Signal)\n",
    "\n",
    "    Extracted_features=np.hstack((maxm, mean, h_mean, median, m_low, m_h, m_g, var,\n",
    "\n",
    "                              std, skewnss, krts, Nkrts, cumfreqs, entrp, shp_f, \n",
    "\n",
    "                              RMS_S, mdst, enrg, IF))\n",
    "\n",
    "    Features_name=pd.DataFrame(['maxm', 'mean','h_mean', 'median', 'm_low', 'm_h', \\\n",
    "\n",
    "                                'm_g', 'var','std', 'skewnss', 'krts', 'Nkrts',\\\n",
    "\n",
    "                                'cumfreqs', 'entrp', 'shp_f', 'RMS_S', 'mdst',\\\n",
    "\n",
    "                                'enrg', 'IF'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n",
    "\n",
    "                                16,17,18,19])\n",
    "\n",
    "    return Extracted_features,Features_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Freq_features(Signal,SR): \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Statistical features from frequency domain signals (FFT signals)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _,FFT_amp=fft_m(Signal,SR,0,1000)\n",
    "\n",
    "    maxm_frq=np.max(FFT_amp) \n",
    "\n",
    "    mean_frq=np.mean(FFT_amp)             #Arithmetic mean of data.\n",
    "\n",
    "    h_mean_frq=stc.harmonic_mean(abs(FFT_amp))  #Harmonic mean of data.\n",
    "\n",
    "    median_frq=stc.median(FFT_amp)             #Median (middle value) of data.\n",
    "\n",
    "    m_low_frq=stc.median_low(FFT_amp)            #Low median of data.\n",
    "\n",
    "    m_h_frq=stc.median_high(FFT_amp)            # High median of data.\n",
    "\n",
    "    m_g_frq=stc.median_grouped(FFT_amp)           # Median, or 50th percentile of grouped data.\n",
    "\n",
    "    var_frq=stc.pvariance(FFT_amp)\n",
    "\n",
    "    std_frq=np.std(FFT_amp)\n",
    "\n",
    "    skewnss_frq=scipy.stats.skew(FFT_amp)\n",
    "\n",
    "    krts_frq=scipy.stats.kurtosis(FFT_amp)\n",
    "\n",
    "    Nkrts_frq=Nrm_Kurtosis(FFT_amp)\n",
    "\n",
    "    cumfreqs_frq=scipy.stats.cumfreq(FFT_amp)[0]\n",
    "\n",
    "    entrp_frq=scipy.stats.entropy(abs(FFT_amp))\n",
    "\n",
    "    shp_f_frq=Shape_factor(FFT_amp)\n",
    "\n",
    "    RMS_frq=RMS(FFT_amp)\n",
    "\n",
    "    mdst_frq=maddest(FFT_amp)\n",
    "\n",
    "    enrg_frq=Energy(FFT_amp)\n",
    "\n",
    "    IF_frq=impulse_factor(FFT_amp)\n",
    "\n",
    "    peak_frq=scipy.signal.find_peaks(FFT_amp,height=max(FFT_amp))[0]*SR/len(Signal)\n",
    "\n",
    "    \n",
    "\n",
    "    Extracted_features=np.hstack((maxm_frq, mean_frq, h_mean_frq, median_frq, m_low_frq,\n",
    "\n",
    "                              m_h_frq, m_g_frq, var_frq, std_frq, skewnss_frq,\n",
    "\n",
    "                              krts_frq, Nkrts_frq, cumfreqs_frq, entrp_frq,\n",
    "\n",
    "                              shp_f_frq, RMS_frq, mdst_frq, enrg_frq, IF_frq))\n",
    "\n",
    "    Features_name=pd.DataFrame(['maxm_frq', 'mean_frq','h_mean_frq', 'median_frq',\n",
    "\n",
    "                            'm_low_frq', 'm_h_frq', 'm_g_frq', 'var_frq','std_frq',\n",
    "\n",
    "                            'skewnss_frq', 'krts_frq', 'Nkrts_frq', 'cumfreqs_frq',\n",
    "\n",
    "                            'entrp_frq', 'shp_f_frq', 'RMS__frq', 'mdst_frq',\n",
    "\n",
    "                            'enrg_frq', 'IF_frq', 'peak_frq'],[1,2,3,4,5,6,7,8,\n",
    "\n",
    "                             9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "\n",
    "    \n",
    "\n",
    "    return Extracted_features,Features_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def All_features(Signal,SR):\n",
    "\n",
    "    S_feat,S_feat_name=Sound_features(Signal,SR)\n",
    "    T_feat,T_feat_name=Time_features(Signal,SR)\n",
    "    Frq_feat,Frq_feat_name=Freq_features(Signal,SR)\n",
    "    All_features=np.hstack((S_feat,T_feat,Frq_feat))  \n",
    "\n",
    "    return All_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbregressor feature importance for feature selection\n",
    "def XGBRgrssr(Features,label,Train_R):\n",
    "\n",
    "    def get_feature_importance_data(Features,label,Train_R):\n",
    "\n",
    "        data = Features.copy()\n",
    "        y = label\n",
    "        X = Features\n",
    "\n",
    "        train_samples = int(X.shape[0] *Train_R)\n",
    "\n",
    "        X_train = X[:train_samples]\n",
    "        X_test = X[train_samples:]\n",
    "\n",
    "        y_train = y[:train_samples]\n",
    "        y_test = y[train_samples:]\n",
    "\n",
    "           return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "    (X_train_FI, y_train_FI), (X_test_FI, y_test_FI) = get_feature_importance_data(All_feat,label,.6)\n",
    "\n",
    "    regressor = xgb.XGBRegressor(gamma=0.0,n_estimators=200,base_score=0.7,colsample_bytree=1,learning_rate=0.001)\n",
    "\n",
    "    xgbModel = regressor.fit(X_train_FI,y_train_FI, \\\n",
    "\n",
    "                         eval_set = [(X_train_FI, y_train_FI), (X_test_FI, y_test_FI)], \\\n",
    "\n",
    "                         verbose=False)\n",
    "\n",
    "    \n",
    "\n",
    "    eval_result = regressor.evals_result()\n",
    "\n",
    "    training_rounds = range(len(eval_result['validation_0']['rmse']))\n",
    "\n",
    "    plt.scatter(x=training_rounds,y=eval_result['validation_0']['rmse'],label='Training Error')\n",
    "\n",
    "    plt.scatter(x=training_rounds,y=eval_result['validation_1']['rmse'],label='Validation Error')\n",
    "\n",
    "    plt.xlabel('Iterations')\n",
    "\n",
    "    plt.ylabel('RMSE')\n",
    "\n",
    "    plt.title('Training Vs Validation Error')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    features_score=xgbModel.feature_importances_.tolist()\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    plt.xticks(rotation='vertical')\n",
    "\n",
    "    X_test_FI=pd.DataFrame(X_test_FI)\n",
    "\n",
    "    plt.bar([i for i in range(len(xgbModel.feature_importances_))], \n",
    "\n",
    "             xgbModel.feature_importances_.tolist(), tick_label=X_test_FI.columns)\n",
    "\n",
    "    plt.title('Feature importance')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    return features_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate feature selection\n",
    "\n",
    "def Unvr_FS(Features,label,N_F):\n",
    "\n",
    "    X=Features\n",
    "    y=label\n",
    "\n",
    "    # Split dataset to select features \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=.6, stratify=y, random_state=0)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    X_indices = np.arange(X.shape[-1])\n",
    "\n",
    "    selector = SelectKBest(f_classif, N_F)\n",
    "    selector.fit(X_train, y_train)\n",
    "    scores = -np.log10(selector.pvalues_)\n",
    "    features_score = scores/max(scores)\n",
    "    plt.bar(X_indices - .45, scores, width=.2,\n",
    "\n",
    "            label=r'Univariate score ($-Log(p_{value})$)', color='darkorange',\n",
    "\n",
    "            edgecolor='black')\n",
    "\n",
    "    plt.title(\"Univariate feature selection\")\n",
    "    plt.xlabel('Feature index')\n",
    "    plt.yticks(())\n",
    "    plt.axis('tight')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    # Compare to the weights of an SVM\n",
    "\n",
    "    clf = make_pipeline(MinMaxScaler(), LinearSVC())\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print('Classification accuracy without selecting features: {:.3f}'\n",
    "\n",
    "          .format(clf.score(X_test, y_test)))\n",
    "\n",
    "    svm_weights = np.abs(clf[-1].coef_).sum(axis=0)\n",
    "\n",
    "    svm_weights /= svm_weights.sum()\n",
    "\n",
    "    plt.bar(X_indices - .25, svm_weights, width=.2, label='SVM weight',\n",
    "\n",
    "        color='navy', edgecolor='black')\n",
    "\n",
    "    clf_selected = make_pipeline(SelectKBest(f_classif, k=10), MinMaxScaler(), LinearSVC())\n",
    "\n",
    "    clf_selected.fit(X_train, y_train)\n",
    "\n",
    "    print('Classification accuracy after univariate feature selection: {:.3f}'\n",
    "\n",
    "          .format(clf_selected.score(X_test, y_test)))\n",
    "\n",
    "    svm_weights_selected = np.abs(clf_selected[-1].coef_).sum(axis=0)\n",
    "\n",
    "    svm_weights_selected /= svm_weights_selected.sum()\n",
    "\n",
    "    plt.bar(X_indices[selector.get_support()] - .05, svm_weights_selected,\n",
    "\n",
    "            width=.2, label='SVM weights after selection', color='c', edgecolor='black')\n",
    "\n",
    "    plt.title(\"Comparing feature selection\")\n",
    "\n",
    "    plt.xlabel('Feature number')\n",
    "\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.axis('tight')\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    return features_score\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "making classifications and predictions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def XGBclass(Features,label,test_r):\n",
    "\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, label,test_size=test_r)\n",
    "\n",
    "    # fit model on training data\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions for test data\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    xx=np.linspace(1,predictions.shape[0],predictions.shape[0])\n",
    "    plt.scatter(xx, y_test, s=1000, color='Blue',label='True condition')\n",
    "    plt.scatter(xx,predictions, s=500, color='red',label='Predicted condition')\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "\n",
    "    return predictions,accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
